{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5780bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer/beerId</th>\n",
       "      <th>beer/name</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47986</td>\n",
       "      <td>Sausa Weizen</td>\n",
       "      <td>A lot of foam. But a lot.\\tIn the smell some b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48213</td>\n",
       "      <td>Red Moon</td>\n",
       "      <td>Dark red color, light beige foam, average.\\tIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48215</td>\n",
       "      <td>Black Horse Black Beer</td>\n",
       "      <td>Almost totally black. Beige foam, quite compac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47969</td>\n",
       "      <td>Sausa Pils</td>\n",
       "      <td>Golden yellow color. White, compact foam, quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64883</td>\n",
       "      <td>Cauldron DIPA</td>\n",
       "      <td>According to the website, the style for the Ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  beer/beerId               beer/name  \\\n",
       "0       47986            Sausa Weizen   \n",
       "1       48213                Red Moon   \n",
       "2       48215  Black Horse Black Beer   \n",
       "3       47969              Sausa Pils   \n",
       "4       64883           Cauldron DIPA   \n",
       "\n",
       "                                         review/text  \n",
       "0  A lot of foam. But a lot.\\tIn the smell some b...  \n",
       "1  Dark red color, light beige foam, average.\\tIn...  \n",
       "2  Almost totally black. Beige foam, quite compac...  \n",
       "3  Golden yellow color. White, compact foam, quit...  \n",
       "4  According to the website, the style for the Ca...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993dec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your dataset (already filtered to top 20 beers)\n",
    "df = pd.read_csv(\"../data/beer_reviews_20.csv\")  # Or whatever your file is\n",
    "df = df[['review/text', 'beer/name']].dropna()\n",
    "\n",
    "# Encode beer names as labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['beer/name'])\n",
    "\n",
    "# Train-val-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df['label'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48fcef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BeerReviewDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.texts = df['review/text'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620d1787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thete\\Github\\dl-final-project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=20)\n",
    "\n",
    "# Optional: Freeze all BERT layers for speed\n",
    "for param in model.distilbert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last 2 layers (layer.4 and layer.5)\n",
    "for i in [4, 5]:\n",
    "    for param in model.distilbert.transformer.layer[i].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "for param in model.distilbert.embeddings.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba2cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "train_dataset = BeerReviewDataset(train_df, tokenizer)\n",
    "val_dataset = BeerReviewDataset(val_df, tokenizer)\n",
    "test_dataset = BeerReviewDataset(test_df, tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,  # Speeds up training on your GPU\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14261bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3513' max='3513' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3513/3513 06:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.185500</td>\n",
       "      <td>1.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.933728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.958769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9337276220321655,\n",
       " 'eval_runtime': 6.0305,\n",
       " 'eval_samples_per_second': 689.99,\n",
       " 'eval_steps_per_second': 10.944,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387dcde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                             60 Minute IPA       0.47      0.55      0.51       495\n",
      "                             90 Minute IPA       0.62      0.57      0.60       658\n",
      "                      Arrogant Bastard Ale       0.67      0.86      0.75       541\n",
      "                        Bell's Hopslam Ale       0.81      0.63      0.71       488\n",
      "            Brooklyn Black Chocolate Stout       0.72      0.73      0.72       489\n",
      "                                     Duvel       0.86      0.81      0.83       490\n",
      "                  Founders Breakfast Stout       0.87      0.77      0.82       500\n",
      "                              HopDevil Ale       0.60      0.55      0.57       460\n",
      "                           La Fin Du Monde       0.83      0.87      0.85       496\n",
      "       Old Rasputin Russian Imperial Stout       0.51      0.70      0.59       622\n",
      "                           Pliny The Elder       0.65      0.79      0.71       506\n",
      "                 Samuel Adams Boston Lager       0.83      0.83      0.83       483\n",
      "Sierra Nevada Bigfoot Barleywine Style Ale       0.91      0.76      0.83       498\n",
      "             Sierra Nevada Celebration Ale       0.66      0.67      0.67       600\n",
      "                    Sierra Nevada Pale Ale       0.60      0.67      0.63       517\n",
      "                Stone IPA (India Pale Ale)       0.47      0.41      0.44       515\n",
      "              Stone Imperial Russian Stout       0.84      0.67      0.74       466\n",
      "                       Stone Ruination IPA       0.54      0.46      0.50       541\n",
      "                          Storm King Stout       0.68      0.59      0.63       490\n",
      "                           Two Hearted Ale       0.50      0.48      0.49       546\n",
      "\n",
      "                                  accuracy                           0.67     10401\n",
      "                                 macro avg       0.68      0.67      0.67     10401\n",
      "                              weighted avg       0.67      0.67      0.67     10401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_df['label'], pred_labels, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3ab67",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bafcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../saved_model/tokenizer_config.json',\n",
       " '../saved_model/special_tokens_map.json',\n",
       " '../saved_model/vocab.txt',\n",
       " '../saved_model/added_tokens.json',\n",
       " '../saved_model/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../saved_model\", safe_serialization=False)\n",
    "tokenizer.save_pretrained(\"../saved_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79628626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_model/label_encoder.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(label_encoder, \"../saved_model/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f8005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
